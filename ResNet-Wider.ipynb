{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import datautils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import models\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 32000 images in 7.00267 seconds\n",
      "X_train:  (24000, 128, 128, 1)\n",
      "y_train:  (24000,)\n",
      "X_val:  (4000, 128, 128, 1)\n",
      "y_val:  (4000,)\n",
      "X_test:  (4000, 128, 128, 1)\n",
      "y_test:  (4000,)\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "num_classes = 250 #250\n",
    "res = 128\n",
    "\n",
    "tic = time.clock()\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, labels = datautils.get_data(num_classes=num_classes, res=128, flip=True)\n",
    "toc = time.clock()\n",
    "print (\"Read {} images in {:5g} seconds\".format(X_train.shape[0] + X_val.shape[0] + X_test.shape[0], toc - tic))\n",
    "print (\"X_train: \", X_train.shape)\n",
    "print (\"y_train: \", y_train.shape)\n",
    "print (\"X_val: \", X_val.shape)\n",
    "print (\"y_val: \", y_val.shape)\n",
    "print (\"X_test: \", X_test.shape)\n",
    "print (\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAEyCAYAAACF03cPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3NmZWSm4szOzUnBnZ2al8P+cuzXlVqvkyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14899d22e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chandelier\n"
     ]
    }
   ],
   "source": [
    "# Plot a random image\n",
    "sample = np.random.randint(X_train.shape[0])\n",
    "plt.imshow(X_train[sample].reshape(128, 128))\n",
    "plt.show()\n",
    "print (labels[y_train[sample]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 250)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "reg_val = 1e0\n",
    "learning_rate = 1e-3\n",
    "dr = 0.5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, res, res, 1])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "lr = tf.placeholder(tf.float32)\n",
    "reg = tf.placeholder(tf.float32)\n",
    "dropout_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "y_out = models.resnet_widish(X, y, \n",
    "                           layer_depth=2, \n",
    "                           num_classes=num_classes, \n",
    "                           is_training=is_training, \n",
    "                           reg=reg,\n",
    "                           dropout=dropout_rate)\n",
    "print (y_out.shape)\n",
    "mean_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(y, num_classes), logits=y_out))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # shuffle indicies\n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indicies)\n",
    "\n",
    "    training_now = training is not None\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss,correct_prediction,accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    for e in range(epochs):\n",
    "                # keep track of losses and accuracy\n",
    "        correct = 0\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "                        # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:], \n",
    "                         y: yd[idx], \n",
    "                         is_training:training_now,\n",
    "                         lr : learning_rate, \n",
    "                         reg: reg_val,\n",
    "                         dropout_rate: dr}\n",
    "                        \n",
    "                        \n",
    "            # get batch size\n",
    "            actual_batch_size = yd[i:i+batch_size].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                                                              .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "                              .format(total_loss,total_correct,e+1))\n",
    "        if plot_losses:\n",
    "            plt.plot(losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()\n",
    "    return total_loss,total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_losses = []\n",
    "train_acc = []\n",
    "val_losses = []\n",
    "val_acc = []\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "model_name = \"resnet-widish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0185, 0.19625, 0.2905, 0.31475, 0.368, 0.45725, 0.4885, 0.4805, 0.26725, 0.54125, 0.5565, 0.54675, 0.51325, 0.56075, 0.5725, 0.62125, 0.62275, 0.6255, 0.621, 0.6205]\n",
      "Best epoch: 18, 0.6255\n",
      "Restoring resnet-widish-18\n",
      "Epoch 1, Overall loss = 1.78 and accuracy of 0.623\n",
      "Test accuracy: 0.623, loss: 1.7795145149230958\n"
     ]
    }
   ],
   "source": [
    "with open(\"./checkpoints/{}.txt\".format(model_name)) as logs:\n",
    "    train_losses = [ float(val) for val in logs.readline().split()[:20] ]\n",
    "    val_losses = [ float(val) for val in logs.readline().split()[:20] ]\n",
    "    train_acc = [ float(val) for val in logs.readline().split()[:20] ]\n",
    "    val_acc = [ float(val) for val in logs.readline().split()[:20] ]\n",
    "\n",
    "print(val_acc)\n",
    "best_epoch = np.argmax(val_acc) + 1\n",
    "print(\"Best epoch: {}, {}\".format(best_epoch, val_acc[best_epoch - 1]))\n",
    "\n",
    "saver.restore(sess, \"./checkpoints/{}-{}\".format(model_name, best_epoch))\n",
    "print(\"Restoring {}-{}\".format(model_name, best_epoch))\n",
    "\n",
    "test_loss, test_acc = run_model(session=sess,\n",
    "                                 predict=y_out,\n",
    "                                 loss_val=mean_loss,\n",
    "                                 Xd=X_test,\n",
    "                                 yd=y_test,\n",
    "                                 epochs=1,\n",
    "                                 batch_size=64,\n",
    "                                 print_every=10000,\n",
    "                                 training=None,\n",
    "                                 plot_losses=False)\n",
    "print(\"Test accuracy: {}, loss: {}\".format(test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./checkpoints/{}.txt\".format(model_name)) as logs:\n",
    "    train_losses = [ float(val) for val in logs.readline().split()[:15] ]\n",
    "    val_losses = [ float(val) for val in logs.readline().split()[:15] ]\n",
    "    train_acc = [ float(val) for val in logs.readline().split()[:15] ]\n",
    "    val_acc = [ float(val) for val in logs.readline().split()[:15] ]\n",
    "\n",
    "saver.restore(sess, \"./checkpoints/{}-{}\".format(model_name, len(val_acc)))\n",
    "print(\"Restoring {}-{}\".format(model_name, len(val_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "reg_val = 1e0\n",
    "learning_rate = 1e-4\n",
    "for i in range(epochs):\n",
    "    loss, acc = run_model(session=sess,\n",
    "                                 predict=y_out,\n",
    "                                 loss_val=mean_loss,\n",
    "                                 Xd=X_train,\n",
    "                                 yd=y_train,\n",
    "                                 epochs=1,\n",
    "                                 batch_size=64,\n",
    "                                 print_every=50,\n",
    "                                 training=train_step,\n",
    "                                 plot_losses=False)\n",
    "    train_losses.append(loss)\n",
    "    train_acc.append(acc)\n",
    "    loss, acc = run_model(session=sess,\n",
    "                                 predict=y_out,\n",
    "                                 loss_val=mean_loss,\n",
    "                                 Xd=X_val,\n",
    "                                 yd=y_val,\n",
    "                                 epochs=1,\n",
    "                                 batch_size=64,\n",
    "                                 print_every=10000,\n",
    "                                 training=None,\n",
    "                                 plot_losses=False)\n",
    "    val_losses.append(loss)\n",
    "    val_acc.append(acc)\n",
    "    saver.save(sess, \"./checkpoints/\" + model_name, global_step=len(val_acc), latest_filename=model_name + \".chkpts\")\n",
    "    f = open(\"./checkpoints/\" + model_name + \".txt\", 'w')\n",
    "    f.write(\" \".join([str(num) for num in train_losses]) + \"\\n\")\n",
    "    f.write(\" \".join([str(num) for num in val_losses]) + \"\\n\")\n",
    "    f.write(\" \".join([str(num) for num in train_acc]) + \"\\n\")\n",
    "    f.write(\" \".join([str(num) for num in val_acc]) + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, len(train_losses) + 1), train_losses, label='Train')\n",
    "plt.plot(np.arange(1, len(train_losses) + 1), val_losses, label='Val')\n",
    "plt.grid(True)\n",
    "plt.axis((0, 20, 0, 10))\n",
    "plt.xticks( np.arange(0, 21, 2) )\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(1, len(train_losses) + 1), train_acc, label='Train')\n",
    "plt.plot(np.arange(1, len(train_losses) + 1), val_acc, label='Val')\n",
    "plt.grid(True)\n",
    "plt.axis((0, 20, 0, 1))\n",
    "plt.xticks( np.arange(0, 21, 2) )\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_model(session=sess,\n",
    "            predict=y_out,\n",
    "            loss_val=mean_loss,\n",
    "            Xd=X_test,\n",
    "            yd=y_test,\n",
    "            epochs=1,\n",
    "            batch_size=64,\n",
    "            print_every=10000,\n",
    "            training=None,\n",
    "            plot_losses=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
